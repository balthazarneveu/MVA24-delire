{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student information\n",
    "Student: Balthazar Neveu\n",
    "\n",
    "🔗 [Github](https://github.com/balthazarneveu/MVA24-delire) | [Online page for this class lab session](https://balthazarneveu.github.io/MVA24-delire)\n",
    "\n",
    "⭐ [Online HTML version of this notebook](https://balthazarneveu.github.io/MVA24-delire/TP_5/tp_5.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYXhEqG-uC3z"
   },
   "source": [
    "# TP Coding a GAN in Pytorch\n",
    "\n",
    "Author : Alasdair Newson\n",
    "\n",
    "alasdair.newson@telecom-paris.fr\n",
    "\n",
    "## Objective:\n",
    "\n",
    "The goal of this TP is to explore GANs applied to the mnist (and possibly cifar10) datasets.\n",
    "\n",
    "We will start with the mnist dataset.\n",
    "\n",
    "### Your task:\n",
    "You need to add the missing parts in the code (parts between # --- START CODE HERE and # --- END CODE HERE or # FILL IN CODE)\n",
    "\n",
    "First of all, let's load some packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "meKYIDlUysj6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "import copy\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "\n",
    "def pytorch_to_numpy(x):\n",
    "    return x.detach().numpy()\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgTDA2KIG4Vm"
   },
   "source": [
    "## 1/ Loading the data\n",
    "\n",
    "We define a function to load the mnist or cifar10 datasets. Note, we normalise the data between -1 and 1 here (this is often the case for GANs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Kq9DHNlPiI3o"
   },
   "outputs": [],
   "source": [
    "\n",
    "# create a random seed for reproducible results\n",
    "random_seed = 1\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "# MNIST Dataset\n",
    "mnist_trainset = datasets.MNIST(root='./mnist_data/', train=True, transform=transform, download=True)\n",
    "mnist_testset = datasets.MNIST(root='./mnist_data/', train=False, transform=transform, download=False)\n",
    "\n",
    "# create data loader with smaller dataset size\n",
    "max_mnist_size = 1000\n",
    "mnist_trainset_reduced = torch.utils.data.random_split(\n",
    "    mnist_trainset, [max_mnist_size, len(mnist_trainset)-max_mnist_size])[0]\n",
    "mnist_train_loader = torch.utils.data.DataLoader(mnist_trainset_reduced, batch_size=64, shuffle=True)\n",
    "\n",
    "# download test dataset\n",
    "max_mnist_size = 512\n",
    "mnist_testset_reduced = torch.utils.data.random_split(\n",
    "    mnist_testset, [max_mnist_size, len(mnist_testset)-max_mnist_size])[0]\n",
    "mnist_test_loader = torch.utils.data.DataLoader(mnist_testset_reduced, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "kpniDL3gekkE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bneveu/.local/lib/python3.10/site-packages/torchvision/datasets/mnist.py:75: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    }
   ],
   "source": [
    "N_ROWS = mnist_trainset_reduced.dataset.train_data.shape[1]\n",
    "N_COLS = mnist_trainset_reduced.dataset.train_data.shape[2]\n",
    "N_CHANNELS = 1\n",
    "N_PIXELS = N_ROWS*N_COLS\n",
    "\n",
    "img_shape = (N_ROWS, N_COLS, N_CHANNELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h25SHO2dT_Uz"
   },
   "source": [
    "## 2/ GAN parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "3l7szkgMT_3C"
   },
   "outputs": [],
   "source": [
    "\n",
    "# GAN parameters\n",
    "Z_DIM = 10\n",
    "BATCH_SIZE = 64\n",
    "# parameters for training\n",
    "n_epochs = 400\n",
    "n_iters_inner = 1  # number of internal loops\n",
    "sample_interval = 100\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "beta_1 = 0.5\n",
    "\n",
    "# hidden dimensions : careful, the order here is with respect to the generator, and the discriminator is in the opposite order\n",
    "H_DIM_1 = 256\n",
    "H_DIM_2 = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vi7BsXCsytEd"
   },
   "source": [
    "## 3/ Model architecture\n",
    "\n",
    "Now, we define the model architecture.\n",
    "\n",
    "For the first dataset, mnist, we are going to use fully connected layers. Implement the following architecture, for the generator and the discriminator :\n",
    "\n",
    "Generator :\n",
    "- Dense layer, to size 256\n",
    "- Leaky ReLU ($\\alpha=0.2$)\n",
    "- Dense layer, to size 512\n",
    "- Leaky ReLU ($\\alpha=0.2$)\n",
    "- Dense layer, output size 784\n",
    "- Tanh activation\n",
    "- Reshape to size $28 \\times 28 \\times 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "in24TH-RESPO"
   },
   "outputs": [],
   "source": [
    "# Generator Code\n",
    "class AdversarialElement(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        z_dim: int = Z_DIM,\n",
    "        h_dim_1: int = H_DIM_1,\n",
    "        h_dim_2: int = H_DIM_2,\n",
    "        n_rows: int = N_ROWS,\n",
    "        n_cols: int = N_COLS,\n",
    "        n_channels: int = N_CHANNELS\n",
    "    ):\n",
    "        super(AdversarialElement, self).__init__()\n",
    "        self.n_rows = n_rows\n",
    "        self.n_cols = n_cols\n",
    "        self.n_channels = n_channels\n",
    "        self.n_pixels = (self.n_rows)*(self.n_cols)\n",
    "        self.h_dim_1 = h_dim_1\n",
    "        self.h_dim_2 = h_dim_2\n",
    "        self.z_dim = z_dim\n",
    "        self.n_pixels = (self.n_rows)*(self.n_cols)\n",
    "        self.non_linear = torch.nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class Generator(AdversarialElement):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.normalize_values = torch.nn.Tanh()\n",
    "        self.fc1 = torch.nn.Linear(self.z_dim, self.h_dim_1)\n",
    "        self.fc2 = torch.nn.Linear(self.h_dim_1, self.h_dim_2)\n",
    "        self.fc3 = torch.nn.Linear(self.h_dim_2, self.n_pixels*self.n_channels)\n",
    "\n",
    "        self.fwd = torch.nn.Sequential(\n",
    "            self.fc1,\n",
    "            self.non_linear,\n",
    "            self.fc2,\n",
    "            self.non_linear,\n",
    "            self.fc3,\n",
    "            self.normalize_values\n",
    "        )\n",
    "\n",
    "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Convert noise vector z into an image-like tensor.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): [N, Z] Noise tensor of size (batch_size, z_dim)\n",
    "\n",
    "        Returns:\n",
    "            x (torch.Tensor): [N, C, H, W] Image tensor of size (batch_size, n_channels, n_rows, n_cols)\n",
    "        \"\"\"\n",
    "        x = self.fwd(z)\n",
    "        x = x.view(-1, self.n_channels, self.n_rows, self.n_cols)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminator :\n",
    "- Flatten\n",
    "- Dense layer, to size 512\n",
    "- Leaky ReLU ($\\alpha=0.2$)\n",
    "- Dense layer, output size 256\n",
    "- Leaky ReLU ($\\alpha=0.2$)\n",
    "- Dense layer, output size 1\n",
    "- Sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "wuXe9NVXOSnD"
   },
   "outputs": [],
   "source": [
    "class Discriminator(AdversarialElement):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.fc1 = nn.Linear(self.n_pixels*self.n_channels, self.h_dim_2)\n",
    "        self.fc2 = nn.Linear(self.h_dim_2, self.h_dim_1)\n",
    "        self.fc3 = nn.Linear(self.h_dim_1, 1)\n",
    "        self.normalize_values = torch.nn.Sigmoid()\n",
    "        self.fwd = torch.nn.Sequential(\n",
    "            self.fc1,\n",
    "            self.non_linear,\n",
    "            self.fc2,\n",
    "            self.non_linear,\n",
    "            self.fc3,\n",
    "            self.normalize_values\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Discriminator forward function.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): [N, C, H, W] Image tensor of size (batch_size, n_channels, n_rows, n_cols)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: probability of the image being real (after sigmoid)\n",
    "        \"\"\"\n",
    "        y = x.view(-1, self.n_pixels*self.n_channels)\n",
    "        y = self.fwd(y)\n",
    "        return y\n",
    "\n",
    "gen_test = Generator(n_channels=4).to(device)\n",
    "out_gen = gen_test(torch.randn(BATCH_SIZE, gen_test.z_dim).to(device))\n",
    "assert out_gen.shape == (\n",
    "    BATCH_SIZE, gen_test.n_channels, gen_test.n_rows, gen_test.n_cols), \"Wrong output size\"\n",
    "\n",
    "disc_test = Discriminator(n_channels=gen_test.n_channels).to(device)\n",
    "proba_real = disc_test(out_gen)\n",
    "assert proba_real.shape == (\n",
    "    BATCH_SIZE, 1), \"Wrong output size\"\n",
    "del gen_test, disc_test, out_gen, proba_real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iq00Ve8OdOXi"
   },
   "source": [
    "Create generator and discriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "FP5lYLacdNyK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (non_linear): LeakyReLU(negative_slope=0.2)\n",
      "  (normalize_values): Tanh()\n",
      "  (fc1): Linear(in_features=10, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=784, bias=True)\n",
      "  (fwd): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=256, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.2)\n",
      "    (4): Linear(in_features=512, out_features=784, bias=True)\n",
      "    (5): Tanh()\n",
      "  )\n",
      ")\n",
      "Discriminator(\n",
      "  (non_linear): LeakyReLU(negative_slope=0.2)\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (normalize_values): Sigmoid()\n",
      "  (fwd): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.2)\n",
      "    (4): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "gen_model = Generator().to(device)\n",
    "# Print the model\n",
    "print(gen_model)\n",
    "\n",
    "disc_model = Discriminator() # FILL IN HERE\n",
    "# Print the model\n",
    "print(disc_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdznIctaESt-"
   },
   "source": [
    "## 4/ Loss function\n",
    "\n",
    "\n",
    "The GAN loss function is the following :\n",
    "\\begin{equation}\n",
    "\t\\min_{G} \\max_{D} \\mathbb{E}_{x \\in p_{data}} \\left[ \\log D(x)\\right] +\n",
    "\t\\mathbb{E}_{z \\in p_{z}}\\left[ \\log \\left( 1 - D(G(z)) \\right)\\right],\n",
    "\\end{equation}\n",
    "where $G$ is the generator, $D$ is the discriminator, $z$ is the latent code, which follows a normal distribution.\n",
    "\n",
    "You should notice that this is extremely similar to the binary cross-entropy function. Therefore, there is an intelligent way to train the discriminator : we give it first a batch of real images, and label them as real, and secondly we give a batch of fake images and label them as fake. Therefore, the discriminator training itself is done in two sequential steps (first true, then fake). If the labels are correctly chosen (further on, during training), you can (and __should__) use the binary cross-entropy function.\n",
    "\n",
    "The generator loss, however, must be specified as :\n",
    "- $mean(\\log(1-D(G(z))))$\n",
    "\n",
    "You can use the ```torch.mean``` function for this purpose.\n",
    "\n",
    "\n",
    "The training is carried out sequentially : first we execute a few training steps on the discriminator, and then one on the generator. Therefore, we use two loops : one to train the discriminator (the internal loop) and one to train the generator (external loop, ie. the number of epochs). The GAN training algorithm is as follows :\n",
    "\n",
    "- For $i=0$ to $n-1$\n",
    "  - For $j=0$ to $m-1$\n",
    "    - $x \\leftarrow$ random batch of data\n",
    "    - $z \\leftarrow$ random batch of latent codes\n",
    "    - Train discriminator on real images $x$\n",
    "    - Train discriminator on fake images $G(z)$\n",
    "  - $z \\leftarrow$ random batch of latent codes\n",
    "  - Train discriminator on fake images $G(z)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SbnxHkOsuDOh"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizer_disc = optim.Adam(disc_model.parameters(), lr=lr, betas=(beta_1, 0.999))\n",
    "optimizer_gen = optim.Adam(gen_model.parameters(), lr=lr, betas=(beta_1, 0.999))\n",
    "\n",
    "# criterion used for the discriminator loss\n",
    "bce_criterion = ...  # FILL IN HERE\n",
    "\n",
    "# criterion used for the generator loss\n",
    "\n",
    "\n",
    "def loss_fn_gen(d_gen_data):\n",
    "    loss_gen = ...  # FILL IN CODE\n",
    "    return loss_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Z0IzHPlLLtb"
   },
   "source": [
    "### Sampling function\n",
    "\n",
    "We now create a function to sample several images during training (to follow the convergence of the network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6oaCO17ZGzWN"
   },
   "outputs": [],
   "source": [
    "\n",
    "def sample_images(generator, z_dim, rand_seed=30):\n",
    "    # np.random.seed(rand_seed)\n",
    "    r, c = 5, 5\n",
    "    z_random = torch.randn(r * c, 1, z_dim, dtype=torch.float, device=device)  # np.random.normal(0, 1, (r * c, z_dim))\n",
    "\n",
    "    gen_imgs = np.transpose(generator(z_random).cpu().detach().numpy(), (0, 2, 3, 1))\n",
    "\n",
    "    # Rescale images 0 - 1\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            # black and white images\n",
    "            if (gen_imgs.shape[3] == 1):\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
    "            elif (gen_imgs.shape[3] == 3):  # colour images\n",
    "                gen_imgs_temp = gen_imgs.copy()\n",
    "                gen_imgs_temp = 255.*np.clip(gen_imgs_temp, 0.0, 1.0)\n",
    "                axs[i, j].imshow(gen_imgs_temp[cnt, :, :, :].astype(np.uint8))\n",
    "            else:\n",
    "                print('Error, unsupported channel size. Dude, I don''t know what you want me to do.\\\n",
    "            I can''t handle this data. You''ve made me very sad ...')\n",
    "            axs[i, j].axis('off')\n",
    "            cnt += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfcwQGo7G0zA"
   },
   "source": [
    "## 5/ Training\n",
    "\n",
    "We are now ready to train the network. Here is the training algorithm again :\n",
    "\n",
    "- For $i=0$ to $n-1$\n",
    "  - For $j=0$ to $m-1$\n",
    "    - $x \\leftarrow$ random batch of data\n",
    "    - $z \\leftarrow$ random batch of latent codes\n",
    "    - Train discriminator on real images $x$\n",
    "    - Train discriminator on fake images $G(z)$\n",
    "  - $z \\leftarrow$ random batch of latent codes\n",
    "  - Train discriminator on fake images $G(z)$\n",
    "\n",
    "You can use ```np.random.normal``` to create a batch of random latent codes, and ```np.random.randint``` to create a batch of random images.\n",
    "\n",
    "You can then train the discriminator and the generator using the ```train_on_batch``` function.\n",
    "\n",
    "We do not worry here about looping over the whole database : just create a random batch at each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gLk9cmsQLL--"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Training Loop\n",
    "\n",
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "\n",
    "sample_interval = 25\n",
    "\n",
    "print(\"Starting Training\")\n",
    "# For each epoch\n",
    "for epoch in range(n_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for i, data in enumerate(mnist_train_loader, 0):\n",
    "        for iter_inner in range(0, n_iters_inner):\n",
    "\n",
    "            ############################\n",
    "            # Train discriminator\n",
    "            ############################\n",
    "            # Train with true data batch\n",
    "            disc_model.zero_grad()\n",
    "            # create true data and labels\n",
    "            true_imgs = ...  # FILL IN HERE\n",
    "            true_labels = ...  # FILL IN HERE\n",
    "            # put true data through discriminator\n",
    "            d_output_true = ...  # FILL IN HERE\n",
    "            # bce loss on true data\n",
    "            d_loss_true = ...  # FILL IN HERE\n",
    "            # backpropagation for discriminator, true loss\n",
    "            d_loss_true.backward()\n",
    "            disc_true_value = d_output_true.mean().item()\n",
    "\n",
    "            # Train with fake data batch\n",
    "            # create fake data and labels\n",
    "            # generate batch of random latent vectors\n",
    "            z_latent_noise = ...  # FILL IN HERE\n",
    "            # Generate batch of fake images\n",
    "            fake_imgs = ...  # FILL IN HERE\n",
    "            fake_labels = ...  # FILL IN HERE\n",
    "            # put fake data through discriminator\n",
    "            disc_output_fake = ...  # FILL IN HERE\n",
    "            # bce loss on fake data\n",
    "            disc_loss_fake = ...  # FILL IN HERE\n",
    "            # backpropagation for discriminator, fake loss\n",
    "            disc_loss_fake.backward()\n",
    "            disc_fake_value = disc_output_fake.mean().item()\n",
    "            # Update discriminator\n",
    "            optimizer_disc.step()\n",
    "\n",
    "            d_loss_total = d_loss_true+disc_loss_fake\n",
    "\n",
    "        ############################\n",
    "        # Train generator\n",
    "        ############################\n",
    "        gen_model.zero_grad()\n",
    "        # We have updated the discriminator, so we need to update the output of the discriminator\n",
    "        disc_gen_output_fake = ...  # FILL IN HERE\n",
    "        # Generator loss, using the custom loss\n",
    "        g_loss = ...  # FILL IN HERE\n",
    "        # backpropagation for generator\n",
    "        g_loss.backward()\n",
    "        # D_G_z2 = output.mean().item()\n",
    "        # Update generator\n",
    "        optimizer_gen.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if i % 200 == 0:\n",
    "            print('[%d/%d][%d/%d] \\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f'\n",
    "                  % (epoch, n_epochs, i, len(mnist_train_loader), d_loss_total.item(), g_loss.item(), disc_true_value, disc_fake_value))\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(g_loss.item())\n",
    "        D_losses.append(d_loss_total.item())\n",
    "\n",
    "    if (epoch % sample_interval == 0):\n",
    "        sample_images(gen_model, z_dim, rand_seed=30)\n",
    "\n",
    "# end samples\n",
    "sample_images(gen_model, z_dim, rand_seed=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51yqyK1IS9m4"
   },
   "source": [
    "## 6/ Navigating in the latent space\n",
    "\n",
    "One of the main interests in the latent space is to be able to __navigate__ in it. For instance, one operation which is very common is to take two points $z_0$ and $z_1$ and to interpolate between the two. The images resulting from the generation of the interpolated points should ideally be a mix between the two initial points. \n",
    "\n",
    "The simplest method of interpolation is simply linear interpolation along the line connecting the two points. Obviously, this supposes that the latent space is linear in some sense, which may not be true, but we are going to take this approach here. \n",
    "\n",
    "First, find two inital points $z_0$ and $z_1$ which you feel represent two different digits well, and display their resulting generated images.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9L3xXcB5S_Ky"
   },
   "outputs": [],
   "source": [
    "# first image\n",
    "random_seed = 110  # change this seed to find the best image\n",
    "torch.manual_seed(random_seed)\n",
    "z_0 = ...  # FILL IN HERE\n",
    "x_0 = ...  # FILL IN HERE\n",
    "\n",
    "random_seed = 64  # change this seed to find the best image\n",
    "torch.manual_seed(random_seed)\n",
    "z_1 = ...  # FILL IN HERE\n",
    "x_1 = ...  # FILL IN HERE\n",
    "\n",
    "# display images\n",
    "# FILL IN HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REs_s6PCS_k5"
   },
   "source": [
    "Now, carry out the interpolation between these two points. You should __include__ the starting and ending codes $z_0$ and $z_1$. Display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sG4H012HXQta"
   },
   "outputs": [],
   "source": [
    "n_interpolation = 20\n",
    "\n",
    "# FILL IN HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GYXEMEvTalzY"
   },
   "outputs": [],
   "source": [
    "# display results\n",
    "\n",
    "fig, axs = plt.subplots(1, n_interpolation, figsize=(20, 20))\n",
    "for i in range(n_interpolation):\n",
    "    # black and white images\n",
    "    axs[i].imshow(..., cmap='gray')  # FILL IN HERE\n",
    "    axs[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yL0VRA7JcRt0"
   },
   "source": [
    "What do you think of the quality of the output images ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAeO6cmVpc5x"
   },
   "source": [
    "__Answer__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnuvaXIrcYal"
   },
   "source": [
    "## 7/ Evaluation of navigation\n",
    "\n",
    "Now, we are going to evaluate this navigation. We will investigate two properties:\n",
    "\n",
    "- 1/ We are going to see whether by navigating between two points, the model produces images which are categorised in either of the classes (beginning class or end class), or if it traverses a region which is categorised in another class;\n",
    "- 2/ We are going to see whether the confidence of a classification network in different regions varies much. In other words, when we navigate in the latent space, do we go into zones which do not correspond to any number (according to the classification network) ? \n",
    "\n",
    "For this, we will first need a classification network. Take the code from the last lab work on variational autoencoders, and extract the section where we trained a classifier on mnist. Here is the architecture we used:\n",
    "\n",
    "- conv2d, filter size  3×3 , 32 filters, stride=(2,2), padding=\"SAME\"\n",
    "- ReLU\n",
    "- conv2d, filter size  3×3 , 32 filters, stride=(2,2), padding=\"SAME\"\n",
    "- ReLU\n",
    "- MaxPool2D, stride=(2,2)\n",
    "- Flatten\n",
    "- Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JOiT7GnOeS1W"
   },
   "outputs": [],
   "source": [
    "# define mnist classifier model, loss function, optimiser and the function 'get_accuracy'\n",
    "\n",
    "# FILL IN HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vpeRKni-ebsp"
   },
   "outputs": [],
   "source": [
    "# training the classifier\n",
    "\n",
    "# FILL IN HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5Xxxm6WfwDM"
   },
   "source": [
    "### 7.1/ Evaluation of navigation 1\n",
    "\n",
    "Now, create a function which returns the classification returned by this network on mnist images. Remember, the classification model above returns the values __before__ the softmax is applied, and here we want the argmax, rather than the maximum probability. __Note__: the torch.max function returns a tuple: (max_values, max_indices).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_QYFnuBlpmug"
   },
   "outputs": [],
   "source": [
    "def predict_mnist_class(imgs_in, classification_model):\n",
    "    output_classes = ...  # FILL IN HERE\n",
    "    return (output_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c2b_Hy_5pqM_"
   },
   "source": [
    "Carry out and print the classification of your interpolated latent space images. What are your remarks ? Does the latent space navigation traverse regions with classes other than those of $z_0$ and $z_1$ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V76E1scdgbRK"
   },
   "outputs": [],
   "source": [
    "z_classes = ...  # FILL IN HERE\n",
    "print(z_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QlXjcZANpzlW"
   },
   "source": [
    "__Answer__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S15dsh-ynwgx"
   },
   "source": [
    "### 7.2/ Evaluation of navigation 2\n",
    "\n",
    "Even though the network may predict coherent image classes during the navigation, it may predict these classes with different confidences. Ideally, we would like the latent space to contain codes which produce images of constant quality. Therefore, as mentioned above, we want to check these prediction confidences during navigation on our GAN.\n",
    "\n",
    "Carry this out now. First of all, define a function which, instead of funding the output *classes* of the interpolations, find the *probability* of the most likely class (the same operation as in the lab on variational autoencoders).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7F2OSEdVoZGo"
   },
   "outputs": [],
   "source": [
    "def predict_mnist_confidence(imgs_in, classification_model):\n",
    "    output_classes = ...  # FILL IN HERE\n",
    "    return (output_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QsdUgb2OooY4"
   },
   "source": [
    "Using this function, carry out the second evaluation on the images generated by interpolated latent codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8SxKQa7Eo90N"
   },
   "outputs": [],
   "source": [
    "z_confidence = ...  # FILL IN HERE\n",
    "print(z_confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvelI7gWpFoS"
   },
   "source": [
    "Does the confidence change greatly during interpolation ? Does the navigation go through zones where the classification is not confident ? Why do you think this is ? (think about the form/shape of the latent space)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZkiGivEKpSc_"
   },
   "source": [
    "__Answer__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKRGvUZaVWK3"
   },
   "source": [
    "# __Optional__ : Training on CIFAR\n",
    "\n",
    "If you want to try another, more challenging database, use the above code and modify it to carry out the GAN training on the CIFAR10 database. Note, it can take a long time to get good results\n",
    "\n",
    "First, we download the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97W-qqT0GtaE"
   },
   "outputs": [],
   "source": [
    "# convert input to Pytorch tensors\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "# extract mnist data\n",
    "cifar_trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "print(cifar_trainset)\n",
    "\n",
    "# create data loader with smaller dataset size\n",
    "max_cifar_size = 2000\n",
    "cifar_trainset_reduced = torch.utils.data.random_split(\n",
    "    cifar_trainset, [max_cifar_size, len(cifar_trainset)-max_cifar_size])[0]\n",
    "cifar_train_loader = torch.utils.data.DataLoader(cifar_trainset_reduced, BATCH_SIZE=64, shuffle=True)\n",
    "\n",
    "# download test dataset\n",
    "cifar_testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "cifar_test_loader = torch.utils.data.DataLoader(cifar_testset, BATCH_SIZE=64, shuffle=True)\n",
    "\n",
    "n_rows = 32\n",
    "n_cols = 32\n",
    "n_channels = 3\n",
    "n_pixels = n_rows*n_cols\n",
    "\n",
    "img_shape = (n_rows, n_cols, n_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxhv31g6NYMS"
   },
   "source": [
    "Now, we can redefine the hyper-parameters of the model (change if you wish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vqp1dLHWNcY2"
   },
   "outputs": [],
   "source": [
    "# GAN parameters\n",
    "z_dim = 10\n",
    "BATCH_SIZE = 64\n",
    "n_epochs = 300\n",
    "# parameters for training\n",
    "n_iters_inner = 1  # number of internal loops\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "beta_1 = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwUdFDCXNevC"
   },
   "source": [
    "For this case of CIFAR, implement the following architecture :\n",
    "\n",
    "- Generator :\n",
    "  - Dense layer to size 1024\n",
    "  - Leaky ReLU ($\\alpha=0.2$)\n",
    "  - Reshape, to size $4 \\times 4 \\times64$\n",
    "  - % size = $4\\times4\\times64$\n",
    "  - Conv2d, n_channels=16,kernel size=(3,3), strides=(1,1),padding=(1,1)\n",
    "  - Upsample(scale_factor=(2,2))\n",
    "  - %size = $8\\times 8\\times 16$\n",
    "  - Leaky ReLU ($\\alpha=0.2$)\n",
    "  - Conv2d, n_channels=16,kernel size=(3,3), strides=(1,1),padding=(1,1)\n",
    "  - Upsample(scale_factor=(2,2))\n",
    "  - %size=$16 \\times 16 \\times 16$\n",
    "  - Leaky ReLU ($\\alpha=0.2$)\n",
    "  - Conv2d, n_channels=3,kernel size=(3,3), strides=(1,1),padding=(1,1)\n",
    "  - Upsample(scale_factor=(2,2))\n",
    "  - %size = $32 \\times 32 \\times 3$\n",
    "  - Tanh activation ( you can use ```Activation('tanh')```)\n",
    "\n",
    "- Discriminator :\n",
    "  - % input size : $32 \\times 32 \\times 3$\n",
    "  - Conv2D, 32 filters, kernel size = (3,3), strides = (1,1),padding = same\n",
    "  - % size $32 \\times 32 \\times 32$\n",
    "  - Leaky ReLU ($\\alpha=0.2$)\n",
    "  - Conv2D, 32 filters, kernel size = (3,3), strides = (2,2),padding = same\n",
    "  - %size : $16 \\times 16 \\times 32$\n",
    "  - Leaky ReLU ($\\alpha=0.2$)\n",
    "  - Conv2D, 64 filters, kernel size = (3,3), strides = (2,2),padding = same\n",
    "  - % size : $8 \\times 8 \\times 64$\n",
    "  - Leaky ReLU ($\\alpha=0.2$)\n",
    "  - Conv2D, 32 filters, kernel size = (3,3), strides = (2,2),padding = same\n",
    "  - % size : $4 \\times 4 \\times 32$\n",
    "  - Leaky ReLU ($\\alpha=0.2$)\n",
    "  - Flatten\n",
    "  - Dense layer to size 1\n",
    "  - Sigmoid activation\n",
    "\n",
    "  Implement this architecture below, and train the GAN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q5m3--yiNhb2"
   },
   "outputs": [],
   "source": [
    "# GAN implementation\n",
    "\n",
    "# FILL IN HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XGz2YT0KR2tX"
   },
   "source": [
    "Now, carry out the training (use code above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQcGMK7YR3JY"
   },
   "outputs": [],
   "source": [
    "# training code\n",
    "\n",
    "# FILL IN HERE"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
