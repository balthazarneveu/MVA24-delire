{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP2\n",
    "- Master MVA ENS-Paris Saclay\n",
    "- Balthazar Neveu\n",
    "- balthazarneveu@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal TV Denoiser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "\n",
    "### Question 2\n",
    "\n",
    "![](figures/single_standalone_awgn_denoisers.png)\n",
    "\n",
    "|Denoiser | RMSE(normalized gray levels) | PSNR(dB) |\n",
    "|:---:|:---:|:---:|\n",
    "|TV Denoiser |  0.0630 | 24.0 dB |\n",
    "|DnCNN Denoiser | 0.0450 | 26.9 dB |\n",
    "| Real SN_DnCNN | 0.0448 | 27.0 dB |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 \n",
    "`RealSN_DnCNN` has the same exact architecture as `DnCNN` but has been trained in a very specific fashion:\n",
    "The residual satisfies the Lipschitz constraint. This will not change anything to the denoising capabilities of the network under AWGN (this is what we observed in the previous table in question 2., additionnally the 2 denoising results look very much alike)\n",
    "The only difference compared to a classic MSE minimization with gradient descent is that the weights are modified during training so that the residual satisfies the Lipschitz constraint (Relu is 1-Lipschitz, Convolutions coefficients at each layer need to be normalized by their largest eigen value). RealSN stands for real Spectral Normalization and uses a \"tricky\" implementation (power method = avoid computing SVD at every training step)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prox_datafit_gaussian_denoising(x, y, alpha, s):\n",
    "    \"\"\"\n",
    "    Proximal Operator for Gaussian denoising:\n",
    "\n",
    "    f(x) = || x - y ||^2 / (2 s^2)\n",
    "\n",
    "    prox_{alpha f} (x) = (x + y*alpha/s^2)/(1+alpha/s^2)\n",
    "\n",
    "    Parameters:\n",
    "        :x - the argument to the proximal operator.\n",
    "        :y - the noisy observation (flattened).\n",
    "        :opts - the kwargs for hyperparameters.\n",
    "            :alpha - the value of alpha.\n",
    "            :s - the standard deviation of the gaussian noise in y.\n",
    "    \"\"\"\n",
    "    a = alpha/(s**2)\n",
    "    v = (x+y*a)/(1+a)\n",
    "    return v\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cheatsheet\n",
    "$\\hat{x} = argmin F(x) + \\lambda G(x)$\n",
    "\n",
    "$\\lambda = \\frac{\\sigma^2}{\\alpha}$ , $\\alpha<1$ to leave a bit of noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
