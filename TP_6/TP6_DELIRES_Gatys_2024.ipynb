{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiCi0qy6HUXs"
      },
      "source": [
        "# ONLY ONCE: DOWNLOAD VGG19 weights\n",
        "#!wget https://partage.imt.fr/index.php/s/4tZx9KPTYJ5cr8L/download -O vgg19.npy\n",
        "!wget https://perso.telecom-paris.fr/ladjal/TP3_DELIRES/vgg19/vgg19.npy -O vgg19.npy\n",
        "!wget  https://perso.telecom-paris.fr/ladjal/TP3_DELIRES/images.tgz -O images.tgz\n",
        "!tar xvzf images.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqQQd4hbIxdg"
      },
      "source": [
        "#import useful libraries\n",
        "#%tensorflow_version 1.x\n",
        "import tensorflow.compat.v1 as tf\n",
        "#import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from functools import reduce\n",
        "from skimage import io as skio\n",
        "import skimage\n",
        "import skimage.transform\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_image(path):\n",
        "\n",
        "    img = skio.imread(path) / 255.0\n",
        "    assert (0 <= img).all() and (img <= 1.0).all()\n",
        "\n",
        "    # Crop image from center\n",
        "    short_edge = min(img.shape[:2])\n",
        "    yy = int((img.shape[0] - short_edge) / 2)\n",
        "    xx = int((img.shape[1] - short_edge) / 2)\n",
        "    shape = list(img.shape)\n",
        "\n",
        "    crop_img = img[yy: yy + short_edge, xx: xx + short_edge]\n",
        "    resized_img = skimage.transform.resize(crop_img, (shape[0], shape[1]))\n",
        "    return resized_img, shape\n",
        "\n",
        "def render_img(session, x, save=False, out_path=None):\n",
        "    shape = x.get_shape().as_list()\n",
        "    img = np.clip(session.run(x), 0, 1.0)*255\n",
        "    img=img.astype(np.uint8)\n",
        "    print(img.shape)\n",
        "    if save:\n",
        "\n",
        "        skio.imsave(out_path,img[0])\n",
        "    else:\n",
        "        viewimage(np.reshape(img, shape[1:]))\n",
        "        #toimage(np.reshape(img, shape[1:])).show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ3Wk54NI2mr"
      },
      "source": [
        "#VGG19 class definition\n",
        "VGG_MEAN = [103.939, 116.779, 123.68]\n",
        "data = None\n",
        "weights_file='./vgg19.npy'\n",
        "\n",
        "class Vgg19:\n",
        "    def __init__(self, vgg19_npy_path=weights_file):\n",
        "        global data\n",
        "\n",
        "\n",
        "        if data is None:\n",
        "            data = np.load(vgg19_npy_path, encoding='latin1',allow_pickle=True)\n",
        "            self.data_dict = data.item()\n",
        "            print(\"VGG19 weights loaded\")\n",
        "\n",
        "        else:\n",
        "            self.data_dict = data.item()\n",
        "\n",
        "    def build(self, rgb, shape):\n",
        "        rgb_scaled = rgb * 255.0\n",
        "        num_channels = shape[2]\n",
        "        channel_shape = shape\n",
        "        channel_shape[2] = 1\n",
        "\n",
        "        # Convert RGB to BGR\n",
        "        red, green, blue = tf.split(axis=3, num_or_size_splits=3, value=rgb_scaled)\n",
        "\n",
        "        assert red.get_shape().as_list()[1:] == channel_shape\n",
        "        assert green.get_shape().as_list()[1:] == channel_shape\n",
        "        assert blue.get_shape().as_list()[1:] == channel_shape\n",
        "\n",
        "        bgr = tf.concat(axis=3, values=[\n",
        "            blue - VGG_MEAN[0],\n",
        "            green - VGG_MEAN[1],\n",
        "            red - VGG_MEAN[2],\n",
        "        ])\n",
        "\n",
        "        shape[2] = num_channels\n",
        "        assert bgr.get_shape().as_list()[1:] == shape\n",
        "\n",
        "        self.conv1_1 = self.conv_layer(bgr, \"conv1_1\")\n",
        "        self.conv1_2 = self.conv_layer(self.conv1_1, \"conv1_2\")\n",
        "        self.pool1 = self.avg_pool(self.conv1_2, 'pool1',self.filtre_moyenneur(64))\n",
        "\n",
        "        self.conv2_1 = self.conv_layer(self.pool1, \"conv2_1\")\n",
        "        self.conv2_2 = self.conv_layer(self.conv2_1, \"conv2_2\")\n",
        "        self.pool2 = self.avg_pool(self.conv2_2, 'pool2',self.filtre_moyenneur(128))\n",
        "\n",
        "        self.conv3_1 = self.conv_layer(self.pool2, \"conv3_1\")\n",
        "        self.conv3_2 = self.conv_layer(self.conv3_1, \"conv3_2\")\n",
        "        self.conv3_3 = self.conv_layer(self.conv3_2, \"conv3_3\")\n",
        "        self.conv3_4 = self.conv_layer(self.conv3_3, \"conv3_4\")\n",
        "        self.pool3 = self.avg_pool(self.conv3_4, 'pool3',self.filtre_moyenneur(256))\n",
        "\n",
        "        self.conv4_1 = self.conv_layer(self.pool3, \"conv4_1\")\n",
        "        self.conv4_2 = self.conv_layer(self.conv4_1, \"conv4_2\")\n",
        "        self.conv4_3 = self.conv_layer(self.conv4_2, \"conv4_3\")\n",
        "        self.conv4_4 = self.conv_layer(self.conv4_3, \"conv4_4\")\n",
        "        self.pool4 = self.avg_pool(self.conv4_4, 'pool4',self.filtre_moyenneur(512))\n",
        "\n",
        "        self.conv5_1 = self.conv_layer(self.pool4, \"conv5_1\")\n",
        "        self.conv5_2 = self.conv_layer(self.conv5_1, \"conv5_2\")\n",
        "        self.conv5_3 = self.conv_layer(self.conv5_2, \"conv5_3\")\n",
        "        self.conv5_4 = self.conv_layer(self.conv5_3, \"conv5_4\")\n",
        "\n",
        "        self.data_dict = None\n",
        "\n",
        "    def filtre_moyenneur(self,nbf):\n",
        "        filtre=np.zeros((2,2,nbf,nbf),np.float32)\n",
        "        for k in range(nbf):\n",
        "            filtre[:,:,k,k]=0.25\n",
        "        return filtre\n",
        "    def avg_pool(self, bottom, name,filtre_inutile):\n",
        "        return tf.nn.avg_pool(bottom,\n",
        "            ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name=name)\n",
        "#    def avg_pool(self, bottom, name,filtre):\n",
        "#        return tf.nn.conv2d(bottom,tf.constant(filtre),strides=[1,2,2,1],padding='SAME',name=name)\n",
        "\n",
        "    def max_pool(self, bottom, name):\n",
        "        return tf.nn.max_pool(bottom,\n",
        "            ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name=name)\n",
        "\n",
        "    def conv_layer(self, bottom, name):\n",
        "        with tf.variable_scope(name):\n",
        "            filt = self.get_conv_filter(name)\n",
        "\n",
        "            conv = tf.nn.conv2d(bottom, filt, [1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "            conv_biases = self.get_bias(name)\n",
        "            bias = tf.nn.bias_add(conv, conv_biases)\n",
        "\n",
        "            relu = tf.nn.relu(bias)\n",
        "            return relu\n",
        "\n",
        "    def fc_layer(self, bottom, name):\n",
        "        with tf.variable_scope(name):\n",
        "            shape = bottom.get_shape().as_list()\n",
        "            dim = 1\n",
        "            for d in shape[1:]:\n",
        "                dim *= d\n",
        "            x = tf.reshape(bottom, [-1, dim])\n",
        "\n",
        "            weights = self.get_fc_weight(name)\n",
        "            biases = self.get_bias(name)\n",
        "\n",
        "            # Fully connected layer. Note that the '+' operation automatically\n",
        "            # broadcasts the biases.\n",
        "            fc = tf.nn.bias_add(tf.matmul(x, weights), biases)\n",
        "\n",
        "            return fc\n",
        "\n",
        "    def get_conv_filter(self, name):\n",
        "        return tf.constant(self.data_dict[name][0], name=\"filter\")\n",
        "\n",
        "    def get_bias(self, name):\n",
        "        return tf.constant(self.data_dict[name][1], name=\"biases\")\n",
        "\n",
        "    def get_fc_weight(self, name):\n",
        "        return tf.constant(self.data_dict[name][0], name=\"weights\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkINBvu2N-lh"
      },
      "source": [
        "#Useful functions for gatys texture synthsis\n",
        "#GATYS Hyperparameters\n",
        "#You must re-excute this cell after changing them\n",
        "TEXTURE_LAYERS = ['conv1_1', 'conv2_1', 'conv3_1', 'conv4_1', 'conv5_1']\n",
        "#TEXTURE_LAYERS = ['conv1_1', 'conv1_2']\n",
        "EPOCHS = 1500\n",
        "LEARNING_RATE = .02\n",
        "\n",
        "NORM_TERM = 2.\n",
        "\n",
        "# Loss term weights\n",
        "TEXTURE_WEIGHT = 3.\n",
        "NORM_WEIGHT = 0.1\n",
        "\n",
        "#END HYPERPARAMETERS\n",
        "\n",
        "# Calcul de la matrice de Gram d'un bloc convolutif\n",
        "def convert_to_gram(filter_maps):\n",
        "    # Get the dimensions of the filter maps to reshape them into two dimenions\n",
        "    dimension = filter_maps.get_shape().as_list()\n",
        "    reshaped_maps = tf.reshape(filter_maps, [dimension[1] * dimension[2], dimension[3]])\n",
        "\n",
        "    # on normalise par la taille spatiale pour obtenir une valeur comparable entre images\n",
        "    return tf.matmul(reshaped_maps, reshaped_maps, transpose_a=True)/((dimension[1] * dimension[2]))\n",
        "\n",
        "\n",
        "# Compute the L2-norm divided by squared number of dimensions\n",
        "def get_l2_norm_loss(diffs):\n",
        "    shape = diffs.get_shape().as_list()\n",
        "    size = reduce(lambda x, y: x * y, shape) ** 2\n",
        "    sum_of_squared_diffs = tf.reduce_sum(tf.square(diffs))\n",
        "    return sum_of_squared_diffs / size\n",
        "\n",
        "\n",
        "# Calcul de la loss texture etant donne le resaeau x et les matrices de gram s\n",
        "def get_texture_loss(x, s):\n",
        "    with tf.name_scope('get_style_loss'):\n",
        "        texture_layer_losses = [get_texture_loss_for_layer(x, s, l) for l in TEXTURE_LAYERS]\n",
        "        texture_weights = tf.constant([1. / len(texture_layer_losses)] * len(texture_layer_losses), tf.float32)\n",
        "        weighted_layer_losses = tf.multiply(texture_weights, tf.convert_to_tensor(texture_layer_losses))\n",
        "        return tf.reduce_sum(weighted_layer_losses)\n",
        "\n",
        "\n",
        "# La loss texture pour une couche particuliere l\n",
        "def get_texture_loss_for_layer(x, s, l):\n",
        "    with tf.name_scope('get_style_loss_for_layer'):\n",
        "\n",
        "        x_layer_maps = getattr(x, l)\n",
        "\n",
        "        x_layer_gram = convert_to_gram(x_layer_maps)\n",
        "        t_layer_gram = s[l]\n",
        "\n",
        "        shape = x_layer_maps.get_shape().as_list()\n",
        "        size = shape[-1]**2\n",
        "        gram_loss = get_l2_norm_loss(x_layer_gram - t_layer_gram)\n",
        "        return gram_loss / size\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwzUlV23JOJV"
      },
      "source": [
        "# Names of images to be created and mimicked\n",
        "OUT_PATH = 'sortie_gatys.png'\n",
        "TEXTURE_PATH = 'images/CRW_3241_1024.png'\n",
        "\n",
        "toto=load_image(TEXTURE_PATH)\n",
        "plt.imshow(toto[0][:256,:256,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_7Q85JoPUDh"
      },
      "source": [
        "# Computation of the Gram matrices for the target texture\n",
        "#Since these are constants, we compute them once and for all.\n",
        "#This is the only information we keep from the example texture\n",
        "sess=tf.Session()\n",
        "\n",
        "texture, image_shape = load_image(TEXTURE_PATH)\n",
        "image_shape = [1] + image_shape\n",
        "texture = texture.reshape(image_shape).astype(np.float32)\n",
        "with tf.name_scope('vgg_texture'):\n",
        "    texture_model = Vgg19()\n",
        "    texture_model.build(texture, image_shape[1:])\n",
        "\n",
        "grams={}\n",
        "# calcul des matrices de gram de l'image d'origine\n",
        "for l in TEXTURE_LAYERS:\n",
        "\n",
        "    #tableau=sess.run(getattr(texture_model,l)) #gettattr renvoie texture_model.l\n",
        "    tableau=(getattr(texture_model,l)).numpy()\n",
        "    tableau=tableau.reshape(tableau.shape[1:])\n",
        "    shape=tableau.shape\n",
        "\n",
        "    tableau=tableau.reshape((shape[0]*shape[1],-1))\n",
        "\n",
        "    grams[l]=np.matmul (tableau.T,tableau)/ (shape[0]*shape[1])\n",
        "\n",
        "\n",
        "\n",
        "sess.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vAPfXofULn3"
      },
      "source": [
        "#Actual optimisation process to produce an image that mimicks the target texture\n",
        "with tf.Session() as sess:\n",
        "    sample_size=[1,512,512,3]\n",
        "    noise_init = tf.truncated_normal(sample_size, mean=.5, stddev=.1)\n",
        "    noise = tf.Variable(noise_init, dtype=tf.float32)\n",
        "\n",
        "\n",
        "\n",
        "    x_model = Vgg19()\n",
        "    x_model.build(noise, sample_size[1:])\n",
        "\n",
        "    # Loss functions\n",
        "    with tf.name_scope('loss'):\n",
        "        # Texture\n",
        "        if TEXTURE_WEIGHT is 0:\n",
        "            texture_loss = tf.constant(0.)\n",
        "        else:\n",
        "            unweighted_texture_loss = get_texture_loss(x_model, grams)#texture_model)\n",
        "            texture_loss = unweighted_texture_loss * TEXTURE_WEIGHT\n",
        "\n",
        "        # Norm regularization\n",
        "        if NORM_WEIGHT is 0:\n",
        "            norm_loss = tf.constant(0.)\n",
        "        else:\n",
        "            norm_loss = (get_l2_norm_loss(noise) ** NORM_TERM) * NORM_WEIGHT\n",
        "\n",
        "        # Total loss\n",
        "        total_loss = texture_loss + norm_loss\n",
        "    # Update image\n",
        "    with tf.name_scope('update_image'):\n",
        "        optimizer = tf.train.AdamOptimizer(LEARNING_RATE)\n",
        "        grads = optimizer.compute_gradients(total_loss, [noise])\n",
        "        clipped_grads = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in grads]\n",
        "        update_image = optimizer.apply_gradients(clipped_grads)\n",
        "\n",
        "    # Train\n",
        "\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    start_time = time.time()\n",
        "    for i in range(EPOCHS):\n",
        "        _, loss = sess.run([update_image, total_loss])\n",
        "        print('etape numero',i,' parmi ',EPOCHS,'loss', loss)\n",
        "\n",
        "    # FIN\n",
        "    elapsed = time.time() - start_time\n",
        "    print(\"Training complete. The session took %.2f seconds to complete.\" % elapsed)\n",
        "    print(\"Rendering final image and closing TensorFlow session..\")\n",
        "\n",
        "    # Render the image after making sure the repo's dedicated output dir exists\n",
        "    #out_dir = os.path.dirname(os.path.realpath(__file__)) + '/../output/'\n",
        "    #if not os.path.isdir(out_dir):\n",
        "    #    os.makedirs(out_dir)\n",
        "    render_img(sess, noise, save=True, out_path=OUT_PATH)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXKl0-8Qec5H"
      },
      "source": [
        "# VIEW the result\n",
        "\n",
        "\n",
        "result=load_image(OUT_PATH)\n",
        "plt.imshow(result[0][:256,:256,:])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}