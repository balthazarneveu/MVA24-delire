{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acc0bfa4",
   "metadata": {},
   "source": [
    "# Diffusion Models for Inverse Problems\n",
    "\n",
    "M2 MVA course, Deep Learning for Image Restoration & Synthesis\n",
    "\n",
    "Authors: Charles Laroche & Andrés Almansa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaa8b13",
   "metadata": {},
   "source": [
    "## I) Setup <a class=\"anchor\" id=\"chapter2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a58926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set home directory containing this notebook + data\n",
    "\n",
    "HOMEDIR = \"/Users/almansa/Home/Docencia/DeLIReS/2024/4-PosteriorSampling/code/TP-DM\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9520567",
   "metadata": {},
   "source": [
    "### Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d74f98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c645bf1",
   "metadata": {},
   "source": [
    "Go to the folder in Google drive where you downloaded the provided code. And check its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4c40ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd HOMEDIR\n",
    "!ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c745963",
   "metadata": {},
   "source": [
    "### Select GPU / CPU\n",
    "\n",
    "By the end of this section `device` should point to a cuda or mps GPU if one is available, otherwise it should point to a CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d69c2b",
   "metadata": {},
   "source": [
    "For google colab: If a cuda GPU is not available, change the runtime type in the Runtime menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c78262",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76d78b8",
   "metadata": {},
   "source": [
    "The following code checks if Apple Silicon or nvidia GPU is available.\n",
    "In that case it sets `device` to \"mps\" or \"cuda\" respectively.\n",
    "Otherwise fallback to `device=\"cpu\"`.\n",
    "If you have access to a TPU in google colab or another non-cuda GPU you may need to change the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e120444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best GPU, fallback to CPU if no GPU is available\n",
    "import os, torch\n",
    "\n",
    "# If Apple Silicon processor is available set device to \"mps\"\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "# If nvidia GPU is available set device to \"cuda\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "# otherwise fallback to \"cpu\"\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print (\"GPU not found using CPU.\")\n",
    "\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da89cbc6",
   "metadata": {},
   "source": [
    "### Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6213955c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install diffusers accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96a885f",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bcc589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import tqdm\n",
    "import utils.utils_image as util\n",
    "import utils.utils_agem as agem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e031db",
   "metadata": {},
   "source": [
    "##  II) DDPM: Denoising Diffusion Probabilistic Models<a class=\"anchor\" id=\"section_2_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6991b09",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa673d8",
   "metadata": {},
   "source": [
    "![DDPM](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/DDPM.png)\n",
    "\n",
    "Denoising diffusion probabilistic models (DDPM) can learn to sample from a distribution of natural images $p(x_0)$. \n",
    "\n",
    "To do so, they first define a forward process that progressively adds Gaussian noise to $x_0$ until $x_T \\sim \\mathcal{N}(0,I)$ :\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "& q(x_{1:T}|x_0) = \\prod_{t=1}^T{q(x_{t}|x_{t-1})} \\\\\n",
    "& q(x_{t}|x_{t-1}) = \\mathcal{N}(x_t;\\sqrt{1-\\beta_t}x_{t-1}, \\beta_t Id) \\\\\n",
    "& x_t = \\sqrt{1-\\beta_t}x_{t-1}  + \\sqrt{\\beta_t} e_t \\quad \\text{where} \\quad e_t \\sim \\mathcal{N}(0,Id) \\\\\n",
    "& x_t = \\sqrt{\\bar{\\alpha_t}}x_{0}  + \\sqrt{1-\\bar{\\alpha_t}} \\epsilon_t \\quad \\text{where} \\quad \\epsilon_t \\sim \\mathcal{N}(0,Id), \\ \\ \\bar{\\alpha_t} = \\prod_{s=1}^t{(1-\\beta_s)}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "In order to sample from $q(x_0)$ we need to estimate the reverse process $q(x_{t-1}|x_{t})$.\n",
    "\n",
    "According to (Feller 1949; [Sohl-Dickstein et al 2015]((https://arxiv.org/pdf/1503.03585.pdf))), if $\\beta_t$ is infinitesimally small then $q(x_{t-1}|x_{t})$ is also Gaussian, so we can approximate it by \n",
    "\n",
    "$$ p_\\theta(x_{t-1}|x_{t}) = \\mathcal{N}(x_t; \\mu_\\theta(x_t,t), \\sigma_t^2 I)$$\n",
    "\n",
    "Using variational inference tools ([Ho et al 2020](https://proceedings.neurips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html)) conclude that\n",
    "\n",
    "- $\\mu_\\theta(x_t,t) = \\frac{1}{\\sqrt{\\alpha_t}} \\left(x_{t} - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha_t}}} \\hat\\epsilon_\\theta(x_t, t)\\right)$\n",
    "\n",
    "- $\\sigma_t^2 = \\frac{1 - \\bar{\\alpha}_{t-1}}{1 - \\bar{\\alpha}_{t}}\\beta_t$\n",
    "\n",
    "where $\\hat\\epsilon_\\theta(x_t,t)$ is a neural network (denoiser) that is trained to predict the noise $\\epsilon_t$ in $x_t = \\sqrt{\\bar{\\alpha_t}}x_{0}  + \\sqrt{1-\\bar{\\alpha_t}}\\epsilon_t$.\n",
    "\n",
    "The DDPM sampling algorithm is summarized as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3060a8ec",
   "metadata": {},
   "source": [
    "***\n",
    "$\\mathbf{\\text{DDPM Algorithm}}$<br>\n",
    "***\n",
    "1.&emsp;Initialize $x_T \\sim \\mathcal{N}(0,1)$<br>\n",
    "2.&emsp;For t = T to 0:<br>\n",
    "&emsp; &emsp; $\\hat\\epsilon = \\epsilon_\\theta(x_t, t)$<br>\n",
    "&emsp; &emsp; $z_t = \\mathcal{N}(0,I)$ <br>\n",
    "&emsp; &emsp; $x_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}} \\left(x_{t} - \\frac{\\beta_t}{\\sqrt{1 - \\bar{\\alpha_t}}}  \\hat\\epsilon \\right) + \\sigma_t z_t$\n",
    "<br>\n",
    "\n",
    "3. Output $x_0$\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd866e1",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be3e9f7",
   "metadata": {},
   "source": [
    "In the sequel we shall need to establish a link between\n",
    "\n",
    "* the noise estimator $\\hat\\epsilon_\\theta$ and\n",
    "* the score function $\\nabla \\log p(x_t)$.\n",
    "\n",
    "This is the goal of the following questions:\n",
    "\n",
    "> **Question 1:** Use the definition of the forward process $x_t \\sim \\mathcal{N}( \\sqrt{\\bar{\\alpha_t}}x_{0},\\,(1-\\bar{\\alpha_t}) I)$ and Tweedie's identity to show that \n",
    "> $ \\widehat{x_0}(x_t) = E[x_0|x_t] = \\frac{1}{\\sqrt{\\bar\\alpha_t}} \\left( x_t + (1-\\bar\\alpha_t) \\nabla \\log p(x_t) \\right) $.\n",
    "\n",
    "> **Question 2:** Use the defition of the forward process $x_t = \\sqrt{\\bar\\alpha_t} x_0 + \\sqrt{1-\\bar\\alpha_t}\\, \\epsilon$ to find an expression of $x_0$ in terms of $\\epsilon$\n",
    "\n",
    "> **Question 3:** Conclude from the two previous results that\n",
    ">\n",
    "> ​\t$\\nabla \\log p(x_t) = - \\frac{1}{\\sqrt{1-\\bar\\alpha_t}} \\hat\\epsilon_\\theta(x_t)$​\n",
    "\n",
    "> **Question 4:** Use the previous result to show that the unconditional DDPM update rule can be written in terms of the score as\n",
    "> $$ x_{t-1}' = \\frac{1}{\\sqrt{\\alpha_t}} \\left(x_{t} + (1 - \\alpha_t) \\nabla \\log p(x_t) \\right) + \\sigma_t z_t$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0412111a",
   "metadata": {},
   "source": [
    "### Using the pipeline\n",
    "\n",
    "Now we are ready to load a pretrained DDPM model and use it to sample from the distribution of face images on which it was trained.\n",
    "\n",
    "To do so we use the diffusers library from HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba6c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DDPMPipeline\n",
    "\n",
    "# Load pretrained model from https://huggingface.co/models?sort=downloads&search=ddpm\n",
    "model_name=\"google/ddpm-ema-celebahq-256\" # 256x256 8 iteratons/second\n",
    "\n",
    "ddpm = DDPMPipeline.from_pretrained(model_name).to(device)\n",
    "image = ddpm(num_inference_steps=100).images[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7263a3c7",
   "metadata": {},
   "source": [
    "### What's behind\n",
    "\n",
    "The pipeline is composed of two main elements:\n",
    "* `unet` is the pretrained score model that is used to predict $x_0$ from $x_t$ and $t$. \n",
    "* `scheduler` contains the values $\\beta_t$, $\\alpha_t$ and $\\bar\\alpha_t$, as well as the function to predict $x_{t-1}$ from $x_t$ and $t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6fff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either load pipeline from pretrained models\n",
    "ddpm = DDPMPipeline.from_pretrained(model_name).to(device)\n",
    "# and then extract scheduler and model\n",
    "scheduler = ddpm.scheduler\n",
    "model = ddpm.unet\n",
    "\n",
    "# Or load scheduler and model directly\n",
    "# from diffusers import DDPMScheduler, UNet2DModel\n",
    "# scheduler = DDPMScheduler.from_pretrained(model_name)\n",
    "# model = UNet2DModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "# You can also try a different scheduler\n",
    "# from diffusers import DDIMScheduler, UNet2DModel\n",
    "# scheduler = DDIMScheduler.from_pretrained(model_name)\n",
    "# model = UNet2DModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "scheduler.set_timesteps(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730b9937",
   "metadata": {},
   "source": [
    "Next we shall use the scheduler and the model to write a lower level version of the DDPM sampling algorithm.\n",
    "\n",
    "Before that,\n",
    "* let's have a look at the scheduler (this requires somme utility functions below)\n",
    "* and let's have a look at the UNet model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d121a1",
   "metadata": {},
   "source": [
    "#### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d00e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler_alpha_t(scheduler, t):\n",
    "    # Get \\bar\\alpha_t and \\alpha_t from scheduler\n",
    "    #   t should be an integer between 0 and T\n",
    "    #   T = scheduler.num_train_timesteps # 1000\n",
    "    prev_t = scheduler.previous_timestep(t)\n",
    "    alpha_prod_t = scheduler.alphas_cumprod[t]\n",
    "    alpha_prod_t_prev = scheduler.alphas_cumprod[prev_t] if prev_t >= 0 else scheduler.one\n",
    "    #beta_prod_t = 1 - alpha_prod_t\n",
    "    #beta_prod_t_prev = 1 - alpha_prod_t_prev\n",
    "    current_alpha_t = alpha_prod_t / alpha_prod_t_prev\n",
    "    #current_beta_t = 1 - current_alpha_t\n",
    "    return alpha_prod_t, current_alpha_t\n",
    "\n",
    "\n",
    "def print_scheduler(scheduler, T, stride):\n",
    "    #T = scheduler.num_train_timesteps # 1000\n",
    "    print(\"T\", \"t\", \"eta_t\", \"alpha_prod_t\", \"beta_prod_t\", \"current_beta_t\")\n",
    "    for t in range(0,T,stride):\n",
    "        alpha_prod_t, current_alpha_t = scheduler_alpha_t(scheduler, t)\n",
    "        beta_prod_t = 1 - alpha_prod_t\n",
    "        current_beta_t = 1 - current_alpha_t\n",
    "        eta_t = current_beta_t / torch.sqrt(current_alpha_t)\n",
    "        print(T, t, eta_t, alpha_prod_t, beta_prod_t, current_beta_t)\n",
    "        \n",
    "def scheduler_alphas(scheduler):\n",
    "    T = scheduler.num_inference_steps # 1000\n",
    "    stride=1\n",
    "    n = T #math.ceil((T+1)/stride)\n",
    "    alpha = torch.zeros(n)\n",
    "    alpha_bar = torch.zeros(n)\n",
    "    time = torch.zeros(n)\n",
    "    for t in range(0,T,stride):\n",
    "        alpha_prod_t, current_alpha_t = scheduler_alpha_t(scheduler, t)\n",
    "        #beta_prod_t = 1 - alpha_prod_t\n",
    "        #current_beta_t = 1 - current_alpha_t\n",
    "        #bt = current_beta_t / torch.sqrt(current_alpha_t)\n",
    "        alpha[t] = current_alpha_t\n",
    "        alpha_bar[t] = alpha_prod_t\n",
    "        time[t] = t\n",
    "    return alpha, alpha_bar, time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a115e56e",
   "metadata": {},
   "source": [
    "#### Explore the scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fca3ce",
   "metadata": {},
   "source": [
    "\n",
    "The variances $\\beta_t$ of the VP (Ornstein Uhlenbeck) forward diffusion process are chosen such that:\n",
    "\n",
    "* $\\bar\\alpha_0$ = 1\n",
    "* $\\bar\\alpha_T = 0$\n",
    "\n",
    "Let's plot the values of $\\bar\\alpha_t$ for $t \\in [0, T]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e76067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T = number of timesteps during training\n",
    "T = scheduler.num_train_timesteps # 1000\n",
    "\n",
    "# TI = number of timesteps during inference\n",
    "TI = T\n",
    "scheduler.set_timesteps(TI)\n",
    "print(scheduler.num_inference_steps)\n",
    "\n",
    "# Get variance schedule\n",
    "alpha, alpha_bar, time = scheduler_alphas(scheduler)\n",
    "\n",
    "# Plot variance schedule\n",
    "plt.plot(time, alpha_bar, label=\"alpha_bar\")\n",
    "\n",
    "# Print variance schedule\n",
    "print_scheduler(scheduler, TI, int(TI/10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95932de1",
   "metadata": {},
   "source": [
    "#### DDPM Sampling in detail\n",
    "\n",
    "Each iteration of the DDPM algorithm is composed of two steps:\n",
    "1. Use the `model` to predict the noise from $x_t$\n",
    "    $$\\hat\\epsilon_t = \\epsilon_\\theta(x_t, t)$$\n",
    "2. Use the `scheduler` to sample $x_{t-1} \\sim p_\\theta(x_{t-1}|x_t)$:\n",
    "    $$x_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}} \\left(x_{t} - \\frac{\\beta_t}{\\sqrt{1 - \\bar{\\alpha_t}}}  \\hat\\epsilon \\right) + \\mathcal{N}(0,\\sigma_t^2 I)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d04465f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddpm_sampling(model, scheduler, n_samples=1):\n",
    "    # Get hyper_params\n",
    "    sample_size = model.config.sample_size\n",
    "    \n",
    "    # Init random noise\n",
    "    x_T = torch.randn((n_samples, 3, sample_size, sample_size)).to(device)\n",
    "    x_t = x_T\n",
    "    \n",
    "    for t in tqdm.tqdm(scheduler.timesteps):\n",
    "        with torch.no_grad():\n",
    "            # Get noisy residual prediction \n",
    "            epsilon_t = model(x_t, t).sample\n",
    "            \n",
    "            # Sample x_{t-1}|x_t \n",
    "            x_t = scheduler.step(epsilon_t, t, x_t).prev_sample\n",
    "\n",
    "    # Normalize output\n",
    "    x_0 = (x_t / 2 + 0.5).clamp(0, 1)\n",
    "    return x_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e4e25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ddpm_sampling(model, scheduler)\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(util.tensor2uint(res))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d849fb",
   "metadata": {},
   "source": [
    "To save time you can also select a smaller number of steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3e90fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TI = 100\n",
    "scheduler.set_timesteps(TI)\n",
    "res = ddpm_sampling(model, scheduler)\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(util.tensor2uint(res))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e3db48",
   "metadata": {},
   "source": [
    "## III) Diffusion models for inverse problems<a class=\"anchor\" id=\"chapter3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb599d71",
   "metadata": {},
   "source": [
    "### Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39274097",
   "metadata": {},
   "source": [
    "\n",
    "Consider an inverse problem with Gaussian likelihood\n",
    "\n",
    "$$p(y|x) = \\mathcal{N}(Hx,\\sigma^2I) $$\n",
    "\n",
    "and prior $p(x)$ given by a diffusion model.\n",
    "\n",
    "Recall from Question 4 that the DDPM update rule can be written in terms of the score function as\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "&  x_{t-1}' = \\frac{1}{\\sqrt{\\alpha_t}} \\left(x_{t} + \\beta_t \\nabla \\log p(x_t) \\right) + \\sigma_t z_t & (1)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "For inverse problems we target the posterior $p(x|y)$ instead of the prior $p(x)$. This means that the score function in the previous equation should be substituted by\n",
    "\n",
    "$$\\nabla_{x_t} \\log{p(x_t|y)} = \\nabla_{x_t} \\log{p_t(x_t)} + \\nabla_{x_t} \\log{p_t(y|x_t)}$$\n",
    "\n",
    "This leads to the following DDPM update rule for posterior sampling\n",
    "$$\n",
    "\\begin{align*}\n",
    "x_{t-1} & = \\frac{1}{\\sqrt{\\alpha_t}} \\left(\n",
    "\t\tx_{t} + \\beta_t (\\nabla \\log p(x_t) + \\nabla \\log p(y|x_t))\n",
    "\\right) + \\sigma_t z_t \n",
    " & (2)\\\\\n",
    "& = \\underbrace{\n",
    "\\frac{1}{\\sqrt{\\alpha_t}} \\left(x_{t} + \\beta_t \\nabla \\log p(x_t) \\right) + \\sigma_t z_t\n",
    "}_{=x_{t-1}'}\n",
    "+ \\frac{\\beta_t}{\\sqrt{\\alpha_t}} \\nabla \\log p(y|x_t) &\n",
    "\\end{align*}\n",
    "$$\n",
    "All the terms in the previous equation are known except for $p_t(y|x_t)$.\n",
    "\n",
    "But we do know $p_t(y|x_0)$.\n",
    "\n",
    "In addition the link between $x_0$ and $x_t$ is provided by the forward and backward process.\n",
    "\n",
    "<div>\n",
    "<img src=\"images_notebook/DPS_distrib.png\" width=\"300\"/>\n",
    "</div>\n",
    "\n",
    "Therefore we could compute the unknown term by marginalization:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\n",
    "& p(y|x_t) = \\int p(x_0|x_t)p(y|x_0)dx_0 & (3)\n",
    "\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The computation of this integral is intractable in general. But it can be computed in closed form if we adopt an approximation of $p(x_0|x_t)$.\n",
    "\n",
    "In the next section, we present two different approximations that provide two conditional sampling algorithms from an unconditional diffusion model: DPS and $\\Pi$GDM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb68326a",
   "metadata": {},
   "source": [
    "### Get a sample from the dataset\n",
    "\n",
    "The dataset below contains:\n",
    "* 20 images $x$ of size 256x256 (from FFHQ face image database)\n",
    "* several blur kernels $k$ of size 33x33 (simulated camera shake kernels)\n",
    "\n",
    "From a given pair $(x, k)$, it generates a blurred and noisy image\n",
    "$$ y = \\underbrace{k * x}_{=H x} + \\mathcal{N}(0,\\sigma^2 Id) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e813f795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data_blur import Dataset\n",
    "from numpy import random\n",
    "\n",
    "data_opt = {'dataroot_H': HOMEDIR + '/data/FFHQ/GT/H',\n",
    "            'dataroot_kernels': HOMEDIR + '/data/kernels/custom_blur_centered.mat',\n",
    "            'sigma': [1,2]}\n",
    "\n",
    "data = Dataset(data_opt)\n",
    "\n",
    "# Get a sample from the dataset\n",
    "k = random.randint(0, 19)\n",
    "sample = data[k]\n",
    "x = sample['H'] # original (ground truth) image - image k\n",
    "k = sample['kernel'] # blur kernel - selected randomly (independently from k)\n",
    "y = sample['L'] # degraded (blurred + noisy) image y = k*x + n\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10/3))\n",
    "plt.subplot(131)\n",
    "plt.imshow(util.tensor2uint(x))\n",
    "plt.axis('off')\n",
    "plt.subplot(132)\n",
    "plt.imshow(util.tensor2uint(k))\n",
    "plt.axis('off')\n",
    "plt.subplot(133)\n",
    "plt.imshow(util.tensor2uint(y))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70345bc4",
   "metadata": {},
   "source": [
    "### Diffusion by Posterior Sampling (DPS)<a class=\"anchor\" id=\"section_3_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aaccec",
   "metadata": {},
   "source": [
    "DPS approximates $p(x_0|x_t)$ by a Dirac centered at the posterior mean $\\widehat{x_0}(x_t) = E[x_0|x_t]$.\n",
    "\n",
    "In other words, $p(x_0|x_t) \\approx \\delta_{\\widehat{x_0}(x_t)}(x_0)$.\n",
    "\n",
    "Substituting this approximation in equation (3) we obtain:\n",
    "\n",
    "$$-\\nabla_{x_t}\\log{p(y|x_t)} = \\nabla_{x_t} {\\frac{1}{2\\sigma^2}\\|H\\widehat{x_0}(x_t) - y\\|_2^2} =: g$$\n",
    "\n",
    "This guidance term $g$ can be computed using automatic differentiation\n",
    "\n",
    "> **Question 5:** Assume that the torch tensor `f` holds the expression $$ -\\log{p(y|x_t)}+C = \\frac{1}{2\\sigma^2} \\|H\\widehat{x_0}(x_t) - y\\|_2^2 =: f.$$ \n",
    "> Use  `torch.autograd.grad` to compute $\\nabla_{x_t} f$. Complete the DPS code below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c656ee5",
   "metadata": {},
   "source": [
    "Combining this with equation (2) above we obtain the **DPS update rule**\n",
    "$$x_{t-1} = x_{t-1}' - \\eta_t g$$\n",
    "\n",
    "where \n",
    "\n",
    "* $x_{t-1}'$ is the update rule for the unconditional DDPM sampler,\n",
    "* $g$ is the guidance term to make it conditional (on the observation $y$), and \n",
    "* $\\eta_t$ is a guidance weight.\n",
    "\n",
    "> **Question 6:** According to equation (2) what should be the value of $\\eta_t$ ? Complete the DPS code below.\n",
    "\n",
    "The authors of DPS prefer to set $\\eta_t = 1$ for all $t$ instead of the theoretical value below. You shall compare both approaches below.\n",
    "\n",
    "> **Question 7:** Assume that the likelihod is not Gaussian, but governed by some Gibbs density $\\log p(y|x_0) +C = \\mathcal{A}(x_0)$. Can you still apply DPS if $\\mathcal{A}$ is differentiable?\n",
    "\n",
    "> **Question 8:** Compare the results of DPS with fixed and adaptive $\\eta_t$ with $\\Pi$GDM below.\n",
    "\n",
    "Reference:\n",
    "- DPS: https://openreview.net/forum?id=OnD9zGAGT0k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f81662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.utils_agem as agem\n",
    "\n",
    "def alpha_beta(scheduler, t):\n",
    "    prev_t = scheduler.previous_timestep(t)\n",
    "    alpha_prod_t = scheduler.alphas_cumprod[t]\n",
    "    alpha_prod_t_prev = scheduler.alphas_cumprod[prev_t] if prev_t >= 0 else scheduler.one\n",
    "    current_alpha_t = alpha_prod_t / alpha_prod_t_prev\n",
    "    current_beta_t = 1 - current_alpha_t\n",
    "    return current_alpha_t, current_beta_t\n",
    "\n",
    "\n",
    "# DPS with DDPM and intrinsic scale\n",
    "def dps_sampling(model, scheduler, y, foward_model, nsamples=1, scale=1, scale_guidance=1):\n",
    "    sample_size = model.config.sample_size\n",
    "    \n",
    "    # Init random noise\n",
    "    x_T = torch.randn((nsamples, 3, sample_size, sample_size)).to(device)\n",
    "    x_t = x_T\n",
    "\n",
    "    for t in tqdm.tqdm(scheduler.timesteps):\n",
    "        \n",
    "        # Predict noisy residual eps_theta(x_t)\n",
    "        x_t.requires_grad_()\n",
    "        epsilon_t = model(x_t, t).sample\n",
    "\n",
    "        # Get x0_hat and unconditional \n",
    "        # x_{t-1} = a_t * x_t + b_t * epsilon(x_t) + sigma_t z_t\n",
    "        # with b_t = eta_t\n",
    "        predict = scheduler.step(epsilon_t, t, x_t) \n",
    "        x0_hat  = agem.clean_output(predict.pred_original_sample)\n",
    "        x_prev  = predict.prev_sample # unconditional DDPM sample x_{t-1}'\n",
    "        \n",
    "        # Guidance\n",
    "        f = torch.norm(forward_model(x0_hat) - y)\n",
    "        g = # ... COMPLETE THIS LINE\n",
    "        \n",
    "        # compute variance schedule\n",
    "        alpha_t, beta_t= alpha_beta(scheduler, t)\n",
    "\n",
    "        # Guidance weight\n",
    "        # eta_t = ...\n",
    "        if (scale_guidance==1):\n",
    "            eta_t =  # ... COMPLETE THIS LINE\n",
    "        else:\n",
    "            eta_t = 1.0\n",
    "\n",
    "        # DPS update rule = DDPM update rule + guidance\n",
    "        x_t = x_prev - scale * eta_t * g\n",
    "        x_t = x_t.detach_()\n",
    "\n",
    "    return agem.clean_output(x_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad16bd9",
   "metadata": {},
   "source": [
    "#### Fixed $\\eta_t =1$\n",
    "\n",
    "Now we are ready to run the DPS algorithm with fixed $\\eta_t = 1$.\n",
    "\n",
    "For best results you should use T=1000 steps. (about 5 minutes)\n",
    "\n",
    "For faster results you can use T=100 steps. (about 30 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfde1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.roll is not supported for MPS device, so we need to enable CPU fallback\n",
    "%env PYTORCH_ENABLE_MPS_FALLBACK=1\n",
    "\n",
    "#scheduler = DDPMScheduler.from_pretrained(model_name)\n",
    "#model = UNet2DModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "ddpm = DDPMPipeline.from_pretrained(model_name).to(device)\n",
    "scheduler = ddpm.scheduler\n",
    "model = ddpm.unet\n",
    "\n",
    "T = 100\n",
    "scheduler.set_timesteps(T)\n",
    "# print_scheduler(scheduler, T, 10)\n",
    "\n",
    "\n",
    "# Forward model (cuda GPU implementation)\n",
    "# forward_model = lambda x: agem.fft_blur(x, sample['kernel'].to(device))\n",
    "# If you are using an MPS gpu use the following forward_model instead\n",
    "# CPU fallback implementation (no MPS support for torch.roll, fft2, Complex Float, etc.)\n",
    "forward_model_cpu = lambda x: agem.fft_blur(x, sample['kernel'])\n",
    "forward_model = lambda x: forward_model_cpu(x.to('cpu')).to(device)\n",
    "# Degraded image y = A x + noise\n",
    "y = sample['L'].to(device)\n",
    "# DPS sampling\n",
    "res = dps_sampling(model, scheduler, y, forward_model, 1, scale=1, scale_guidance=0)\n",
    "# Ground truth image x\n",
    "x = sample['H'].to(device)\n",
    "\n",
    "plt.figure(figsize=(10, 10/3))\n",
    "plt.subplot(131)\n",
    "plt.imshow(util.tensor2uint(y))\n",
    "plt.axis('off')\n",
    "plt.subplot(132)\n",
    "plt.imshow(util.tensor2uint(res))\n",
    "plt.axis('off')\n",
    "plt.subplot(133)\n",
    "plt.imshow(util.tensor2uint(x))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "import utils.utils_image as image_utils\n",
    "image_utils.calculate_psnr(util.tensor2uint(res), util.tensor2uint(sample['H']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75aa80e",
   "metadata": {},
   "source": [
    "#### Adaptive $\\eta_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cda0941",
   "metadata": {},
   "source": [
    "Now we are ready to run the DPS algorithm with the theoretical (adaptive) values of $\\eta_t$.\n",
    "\n",
    "First have a look at the scheduler to see how $\\eta_t$ varies with $t$.\n",
    "`print_scheduler(scheduler, T, 10)`\n",
    "Then set the value of the scale paraameter accordingly.\n",
    "\n",
    "For best results you should use T=1000 steps. (about 5 minutes)\n",
    "\n",
    "For faster results you can use T=100 steps. (about 30 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f814870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.roll is not supported for MPS device, so we need to enable CPU fallback\n",
    "%env PYTORCH_ENABLE_MPS_FALLBACK=1\n",
    "\n",
    "#scheduler = DDPMScheduler.from_pretrained(model_name)\n",
    "#model = UNet2DModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "ddpm = DDPMPipeline.from_pretrained(model_name).to(device)\n",
    "scheduler = ddpm.scheduler\n",
    "model = ddpm.unet\n",
    "\n",
    "T = 100\n",
    "scheduler.set_timesteps(T)\n",
    "print_scheduler(scheduler, T, 10)\n",
    "\n",
    "\n",
    "# Forward model (cuda GPU implementation)\n",
    "# forward_model = lambda x: agem.fft_blur(x, sample['kernel'].to(device))\n",
    "# If you are using an MPS gpu use the following forward_model instead\n",
    "# CPU fallback implementation (no MPS support for torch.roll, fft2, Complex Float, etc.)\n",
    "forward_model_cpu = lambda x: agem.fft_blur(x, sample['kernel'])\n",
    "forward_model = lambda x: forward_model_cpu(x.to('cpu')).to(device)\n",
    "# Degraded image y = A x + noise\n",
    "y = sample['L'].to(device)\n",
    "# DPS sampling\n",
    "res = dps_sampling(model, scheduler, y, forward_model, 1, scale=100, scale_guidance=1)\n",
    "# Ground truth image x\n",
    "x = sample['H'].to(device)\n",
    "\n",
    "plt.figure(figsize=(10, 10/3))\n",
    "plt.subplot(131)\n",
    "plt.imshow(util.tensor2uint(y))\n",
    "plt.axis('off')\n",
    "plt.subplot(132)\n",
    "plt.imshow(util.tensor2uint(res))\n",
    "plt.axis('off')\n",
    "plt.subplot(133)\n",
    "plt.imshow(util.tensor2uint(x))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "import utils.utils_image as image_utils\n",
    "image_utils.calculate_psnr(util.tensor2uint(res), util.tensor2uint(sample['H']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0e7660",
   "metadata": {},
   "source": [
    "### 2)  Pseudoinverse-Guided Diffusion Models ($\\Pi$GDM))<a class=\"anchor\" id=\"section_3_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73135c45",
   "metadata": {},
   "source": [
    "In $\\Pi$GDM, $p(x_0|x_t)$ is approximated with a Gaussian distribution. We have $p(x_0|x_t)\\sim \\mathcal{N}(\\widehat{x_0}, r_t^2)$.\n",
    "\n",
    "Now since both $p(x_0|x_t)$ and $p(y|x_0)$ are Gaussian, we can compute the posterior $p(y|x_t)$ in closed form:\n",
    "\n",
    "$$p(y|x_t) \\sim \\mathcal{N}(H\\widehat{x_0}, r_t^2 HH^T + \\sigma^2Id)$$\n",
    "\n",
    "which leads to:\n",
    "$$\\nabla_{x_t} \\log{p(y|x_t)} = \\left(\\frac{\\partial \\widehat{x_0}(x_t)}{\\partial x_t}\\right)^T H^T (r_t^2 HH^T + \\sigma^2Id)^{-1} (y - H \\widehat{x_0})$$\n",
    "\n",
    "Autograd is able to do most of the job, but we still need to invert $(r_t^2 HH^T + \\sigma^2Id)$. This computation can be expensive, unless $H$ has some special structure. For deblurring, $H$ is a convolution operator, so we can use the FFT to compute the inverse efficiently.\n",
    "\n",
    "***\n",
    "\n",
    "$\\Pi$GDM \"guidance\" is more efficient that DPS, which means we do not need as much iterations as DPS (between 50 and 100). However, the cost of a strong guidance comes with limitations on the complexity of the forward operator $H$.\n",
    "\n",
    "Reference:\n",
    "- $\\Pi$GDM: https://openreview.net/forum?id=9_gsMA8MRKQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c4389a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env PYTORCH_ENABLE_MPS_FALLBACK=1\n",
    "import torch.fft as fft\n",
    "\n",
    "def pinv_deblurring(x, k, r=1, sigma=1e-8):\n",
    "    k = agem.p2o(k, x.shape[-2:])\n",
    "    Fk = fft.fft2(k)\n",
    "    FkC = Fk.conj()\n",
    "    Fk2 = Fk.mul(FkC)\n",
    "    num = FkC\n",
    "    den = r ** 2 * Fk2 + sigma ** 2\n",
    "    res = (num / den) * fft.fft2(x)\n",
    "    return fft.ifft2(res).real\n",
    "\n",
    "def deblurring_guidance(y, x, k, sigma=0, r=1):\n",
    "    if sigma == 0:\n",
    "        sigma += 1e-8\n",
    "    if (device == torch.device(\"mps\")):\n",
    "        # Enable CPU fallback for FFT operations\n",
    "        y = y.to(\"cpu\")\n",
    "        x = x.to(\"cpu\")\n",
    "        k = k.to(\"cpu\")\n",
    "        result = pinv_deblurring(y, k, r=r, sigma=sigma) - pinv_deblurring(agem.fft_blur(x, k), k, r=r, sigma=sigma)\n",
    "        result = result.to(device)\n",
    "    else:\n",
    "        result = pinv_deblurring(y, k, r=r, sigma=sigma) - pinv_deblurring(agem.fft_blur(x, k), k, r=r, sigma=sigma)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb1173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pigdm_sampling(model, scheduler, y, sigma, guidance, n, scale=1):    \n",
    "    sample_size = model.config.sample_size\n",
    "    step_size = scheduler.config.num_train_timesteps // scheduler.num_inference_steps\n",
    "    \n",
    "    # Init random noise\n",
    "    input = torch.randn((n, 3, sample_size, sample_size)).to(device)\n",
    "\n",
    "    for t in tqdm.tqdm(scheduler.timesteps):\n",
    "        # Computation of some hyper-params\n",
    "        prev_t = t - step_size\n",
    "        variance = scheduler._get_variance(t, prev_t)\n",
    "        r = torch.sqrt(variance/(variance + 1))\n",
    "        current_alpha_t = 1 / (1 + variance)\n",
    "\n",
    "        # Predict noise\n",
    "        input.requires_grad_()\n",
    "        noisy_residual = model(input, t).sample\n",
    "\n",
    "        # Get x_prec and x0_hat\n",
    "        pred = scheduler.step(noisy_residual, t, input)\n",
    "        x0_hat = agem.clean_output(pred.pred_original_sample)\n",
    "        x_prec = pred.prev_sample\n",
    "\n",
    "        # Guidance\n",
    "        g = (guidance(y, x0_hat, sigma=sigma, r=r).detach() * x0_hat).sum()\n",
    "        grad = torch.autograd.grad(outputs=g, inputs=input)[0]\n",
    "        input = input.detach_()\n",
    "\n",
    "        # Update of x_t\n",
    "        input = x_prec + scale * grad * (r ** 2) * torch.sqrt(current_alpha_t)\n",
    "\n",
    "    return agem.clean_output(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38920e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scheduler = DDIMScheduler.from_pretrained(\"google/ddpm-celebahq-256\")\n",
    "#model = UNet2DModel.from_pretrained(\"google/ddpm-celebahq-256\").to(\"cuda\")\n",
    "\n",
    "ddpm = DDPMPipeline.from_pretrained(model_name).to(device)\n",
    "scheduler = ddpm.scheduler\n",
    "model = ddpm.unet\n",
    "scheduler.set_timesteps(100)\n",
    "\n",
    "guidance = lambda y, x, sigma, r: deblurring_guidance(y, x, sample['kernel'].to(device), sigma=sigma, r=r)\n",
    "res = pigdm_sampling(model, scheduler, sample['L'].to(device), sample['sigma'], guidance, 1)\n",
    "\n",
    "plt.figure(figsize=(10, 10/3))\n",
    "plt.subplot(131)\n",
    "plt.imshow(util.tensor2uint(sample['L']))\n",
    "plt.axis('off')\n",
    "plt.subplot(132)\n",
    "plt.imshow(util.tensor2uint(res))\n",
    "plt.axis('off')\n",
    "plt.subplot(133)\n",
    "plt.imshow(util.tensor2uint(sample['H']))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "import utils.utils_image as image_utils\n",
    "image_utils.calculate_psnr(util.tensor2uint(res), util.tensor2uint(sample['H']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusers2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
